---
title: "Why Bambi?"
author: "Tomás Capretto"
date: 2021-05-22
output: html_document
description: A quick example comparing how to fit a GLM with Bambi and PyMC3
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>I’ve been thinking about writing a new blog post for a while now, and it was
just a few hours ago that I realized I could write about something quite curious
that happened to me while trying to replicate a <a href="https://bambinos.github.io/bambi/">Bambi</a>
model with <a href="https://docs.pymc.io/">PyMC3</a>.</p>
<p>A couple of weeks ago <a href="https://twitter.com/AgustinaArroyu1">Agustina Arroyuelo</a>
told me she was trying to replicate a <a href="https://bambinos.github.io/bambi/master/notebooks/wald_gamma_glm.html#Wald">model</a>
in an example notebook in Bambi and wanted my opinion on what she was doing.
After many attempts, neither of us could replicate the model successfully. It
turned out to be we were messing up with the shapes of the priors and also had
some troubles with the design matrix.</p>
<p>Let’s go straight to our problem and see how Bambi can make our Bayesian
modeling life much easier.</p>
</div>
<div id="setup" class="section level2">
<h2>Setup</h2>
<p>We use the <code>reticulate</code> package to enable Python in our R Markdown document.
<code>"rbambi"</code> is just a conda environment that has the latest version of Bambi
installed.</p>
<pre class="r"><code>library(ggplot2)
library(reticulate)
use_condaenv(&quot;rbambi&quot;, required = TRUE)
knitr::opts_chunk$set(eval = TRUE)</code></pre>
<pre class="python"><code>import arviz as az
import bambi as bmb
import numpy as np
import pandas as pd
import pymc3 as pm
import theano.tensor as tt

np.random.seed(1234)</code></pre>
</div>
<div id="the-problem" class="section level2">
<h2>The problem</h2>
<p>In this notebook we use a data set consisting of 67856 insurance policies and
4624 (6.8%) claims in Australia between 2004 and 2005.
The original source of this dataset is the book <a href="http://www.businessandeconomics.mq.edu.au/our_departments/Applied_Finance_and_Actuarial_Studies/research/books/GLMsforInsuranceData">Generalized Linear Models for
Insurance Data</a>
by Piet de Jong and Gillian Z. Heller.</p>
<pre class="python"><code>data = pd.read_csv(
  &quot;https://courses.ms.ut.ee/2020/glm/spring/uploads/Main/carclaims.csv&quot;
)
data = data[data[&quot;claimcst0&quot;] &gt; 0]</code></pre>
<p>In this example we are going to use the binned age, the gender, and the area of
residence to predict the amount of the claim, conditional on the existence of
the claim because we are only working with observations where there is a claim.</p>
</div>
<div id="model-with-pymc3" class="section level2">
<h2>Model with PyMC3</h2>
<p>To fit the model with PyMC3 we first need to create the model matrix. We need
to represent <code>age</code>, <code>area</code>, and <code>gender</code> with dummy variables because they are
categoric. We can think of the following objects as sub-matrices of the
design matrix in the model.</p>
<pre class="python"><code>intercept = np.ones((len(data), 1))
age = pd.get_dummies(data[&quot;agecat&quot;], drop_first=True).to_numpy()
area = pd.get_dummies(data[&quot;area&quot;], drop_first=True).to_numpy()
gender = pd.get_dummies(data[&quot;gender&quot;], drop_first=True).to_numpy()</code></pre>
<p>Then we just stack horizontally these sub-matrices and convert the result to a
Theano tensor variable so we can compute the dot product between this matrix and
the vector of coefficients.</p>
<pre class="python"><code>X = np.hstack([intercept, age, area, gender])
X = tt.as_tensor_variable(X)</code></pre>
<div id="fit" class="section level3">
<h3>Fit</h3>
<p>We start declaring the priors for each of the predictors in the model. They are
all independent Gaussian distributions. You may wonder where I took the values
for the parameters of these distributions. They are similar to Bambi’s default
values for this particular problem, but they are not the main issue in this
post.</p>
<p>At this stage, it is extremely important to give appropiate shapes to all the
objects we create in the model. For example, <code>β_age</code> is a random variable that
represents the coefficients for the age variable. Since 5 dummy variables are
used to represent the age, <code>β_age</code> has <code>shape=(5, 1)</code>, as well as the arrays
passed to <code>mu</code> and <code>sigma</code>.</p>
<pre class="python"><code># Create model and sample posterior
with pm.Model() as model_pymc3:  
    # Build predictors
    β_0 = pm.Normal(
        &quot;β_0&quot;, 
        mu=np.array([[10]]), 
        sigma=np.array([[3]]),
        shape=(1, 1)
    )  
    β_age = pm.Normal(
        &quot;β_age&quot;,       
        mu=np.array([[0] * 5]).T, 
        sigma=np.array([[5] * 5]).T,
        shape=(5, 1)
    )
    β_gender = pm.Normal(
        &quot;β_gender&quot;, 
        mu=np.array([[0]]), 
        sigma=np.array([[1.304491]]),
        shape=(1, 1)
    )
    β_area = pm.Normal(
        &quot;β_area&quot;, 
        mu=np.array([[0] * 5]).T, 
        sigma=np.array([[5] * 5]).T,
        shape=(5, 1)
    )
    
    # Compute linear predictor
    β = tt.concatenate([β_0, β_age, β_gender, β_area], axis=0)
    # Transform linear predictor
    mu = tt.exp(X.dot(β))
      
    response = np.array([data[&quot;claimcst0&quot;]]).T
    pm.Wald(
      &quot;claim&quot;, 
      mu=mu, 
      lam=pm.HalfCauchy(&quot;claim_lam&quot;, beta=1), 
      observed=response
    )
    idata_pymc = pm.sample(tune=2000, return_inferencedata=True)</code></pre>
<pre><code>## claim
## █
## Auto-assigning NUTS sampler...
## Initializing NUTS using jitter+adapt_diag...
## Multiprocess sampling (2 chains in 2 jobs)
## NUTS: [claim_lam, β_area, β_gender, β_age, β_0]
## Sampling 2 chains for 2_000 tune and 1_000 draw iterations (4_000 + 2_000 draws total) took 16 seconds.</code></pre>
</div>
</div>
<div id="fil-model-with-bambi" class="section level2">
<h2>Fil model with Bambi</h2>
<pre class="python"><code>model_bambi= bmb.Model(
  &quot;claimcst0 ~ C(agecat) + gender + area&quot;, 
  data, family = &quot;wald&quot;, link = &quot;log&quot;
)
idata_bambi = model_bambi.fit(tune=2000)</code></pre>
<pre><code>## █
## Auto-assigning NUTS sampler...
## Initializing NUTS using jitter+adapt_diag...
## Multiprocess sampling (2 chains in 2 jobs)
## NUTS: [claimcst0_lam, area, gender, C(agecat), Intercept]
## Sampling 2 chains for 2_000 tune and 1_000 draw iterations (4_000 + 2_000 draws total) took 17 seconds.
## The acceptance probability does not match the target. It is 0.8869722493127511, but should be close to 0.8. Try to increase the number of tuning steps.</code></pre>
</div>
<div id="check-results-are-equivalent" class="section level2">
<h2>Check results are equivalent</h2>
<pre class="python"><code>summary_pymc = az.summary(idata_pymc)
summary_bambi = az.summary(idata_bambi)</code></pre>
<pre class="r"><code>summary_pymc = py$summary_pymc[1:4]
summary_bambi = py$summary_bambi[1:4]

names = c(
  &quot;β_0&quot;, &quot;β_age[0]&quot;, &quot;β_age[1]&quot;, &quot;β_age[2]&quot;, &quot;β_age[3]&quot;, &quot;β_age[4]&quot;,
  &quot;β_gender&quot;, &quot;β_area[0]&quot;, &quot;β_area[1]&quot;, &quot;β_area[2]&quot;, &quot;β_area[3]&quot;,
  &quot;β_area[4]&quot;, &quot;λ&quot;
)
summary_pymc$row = seq(1, 26, by = 2) + 0.25
summary_bambi$row = seq(1, 26, by = 2)  - 0.25
summary_pymc$model = &quot;PyMC3&quot;
summary_bambi$model = &quot;Bambi&quot;
summary_pymc$names = names
summary_bambi$names = names
summary_pymc$panel = c(&quot;Intercept&quot;, rep(&quot;Effects&quot;, 11), &quot;Dispersion&quot;)
summary_bambi$panel = c(&quot;Intercept&quot;, rep(&quot;Effects&quot;, 11), &quot;Dispersion&quot;)
summary = rbind(summary_pymc, summary_bambi)</code></pre>
<pre class="r"><code>ggplot(summary, aes(color = model)) +
  geom_point(aes(mean, row)) +
  geom_segment(aes(x = `hdi_3%`, xend=`hdi_97%`, y = row, yend = row)) + 
  facet_grid(cols = vars(panel), scales = &quot;free&quot;)</code></pre>
<p><img src="/post/bambi-wald_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="conclusion" class="section level2">
<h2>Conclusion</h2>
</div>
